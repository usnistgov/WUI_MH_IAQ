"""
WUI DustTrak PM vs Relative Humidity Comparison Analysis

This script investigates the relationship between DustTrak PM2.5 measurements
and relative humidity (RH) during wildland-urban interface smoke experiments.
It evaluates potential humidity artifacts in optical PM measurements.

Research Motivation:
    - Optical instruments can be affected by particle hygroscopic growth
    - High RH can cause water uptake, increasing apparent PM
    - Understanding RH effects is critical for accurate exposure assessment

Analysis Components:
    1. PM2.5 vs RH correlation analysis
    2. Temporal cross-correlation (lag analysis)
    3. RH correction factor development
    4. Before/after correction comparison

Key Questions:
    - Is there a significant RH dependence in DustTrak readings?
    - What is the critical RH threshold for hygroscopic effects?
    - How do smoke particles differ from ambient aerosol RH response?
    - Should RH corrections be applied to this data?

Methodology:
    - Pearson and Spearman correlation coefficients
    - Segmented analysis (low RH vs high RH periods)
    - Hysteresis detection (RH increasing vs decreasing)
    - Multivariate analysis (PM vs RH and temperature)

Data Sources:
    - DustTrak PM measurements (bedroom)
    - RH/Temperature sensors (multiple locations)
    - Burn log with environmental conditions

Quality Control:
    - Temperature stability verification
    - Sensor calibration check
    - Outlier detection and removal

Outputs:
    - PM vs RH scatter plots (color-coded by time)
    - Time series overlay plots
    - Correlation analysis summary
    - RH correction recommendations

Dependencies:
    - pandas: Data processing
    - numpy: Statistical calculations
    - bokeh: Interactive plotting
    - scipy: Advanced statistics

Configuration:
    - Path configuration for multiple systems
    - RH threshold definitions
    - Smoothing parameters

Author: Nathan Lima
Date: 2024-2025
"""

# %%
# Import needed modules
print("Importing needed modules")
import os
import numpy as np
import pandas as pd
from datetime import datetime as dt
import datetime
from bokeh.plotting import figure, show
from bokeh.io import output_notebook, output_file
from bokeh.models import ColumnDataSource, LinearAxis, Range1d, Legend, Div
from bokeh.layouts import column

import sys
from pathlib import Path

# Add repository root to path for portable data access
script_dir = Path(__file__).parent
repo_root = script_dir.parent
sys.path.insert(0, str(repo_root))

from src.data_paths import get_data_root, get_instrument_path, get_common_file


# Path configuration now handled by portable data_paths module
# Old system detection code removed - using get_data_root() instead
data_root = get_data_root()

os.chdir(str(data_root))

# Load burn log for date reference
burn_log_path = str(get_common_file('burn_log'))
burn_log = pd.read_excel(burn_log_path, sheet_name="Sheet2")

# Get first and last burn dates to filter continuous data
first_burn_date = pd.to_datetime(burn_log["Date"].min()).date()
last_burn_date = pd.to_datetime(burn_log["Date"].max()).date()
print(f"Date range: {first_burn_date} to {last_burn_date}")

# Define burn styles for plotting
BURN_STYLES = {
    "burn1": {"color": "#ef5675", "line_dash": "solid"},
    "burn2": {"color": "#d45087", "line_dash": "solid"},
    "burn3": {"color": "#b35093", "line_dash": "dashed"},
    "burn4": {"color": "#b35093", "line_dash": "solid"},
    "burn5": {"color": "#8d5196", "line_dash": "solid"},
    "burn6": {"color": "#665191", "line_dash": "solid"},
    "burn7": {"color": "#404e84", "line_dash": "solid"},
    "burn8": {"color": "#404e84", "line_dash": "dashed"},
    "burn9": {"color": "#003f5c", "line_dash": "solid"},
    "burn10": {"color": "#003f5c", "line_dash": "dashed"},
}

# Define burn labels for legend
BURN_LABELS = {
    "burn1": "01-House",
    "burn2": "02-House-4-N",
    "burn3": "03-House-1-U",
    "burn4": "04-House-1-N",
    "burn5": "05-Room",
    "burn6": "06-Room-1-N",
    "burn7": "07-House-2A-N",
    "burn8": "08-House-2A-U",
    "burn9": "09-House-2-N",
    "burn10": "10-House-2-U",
}


# Function to get script metadata
def get_script_metadata():
    """Return a string with script name and execution timestamp"""
    # Try to get the script name using inspect module (works well in VSCode interactive window)
    try:
        import inspect

        script_name = os.path.basename(
            inspect.getmodule(inspect.currentframe()).__file__
        )
    except (NameError, AttributeError, TypeError):
        # If inspect method fails, try __file__ approach
        try:
            script_name = os.path.basename(__file__)
        except NameError:
            # Final fallback
            script_name = "unknown_script.py"

    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    return f"Generated by: {script_name} | Date: {timestamp}"


def process_dusttrak_data():
    """
    Process DustTrak data with standardized output format,
    based on wui_clean_air_delivery_rates_pmsizes_update5.py
    """
    print("Loading DustTrak data...")

    # Load the DustTrak data from all_data.xlsx
    dusttrak_data = pd.read_excel("./burn_data/dusttrak/all_data.xlsx")

    # Strip whitespace from column names
    dusttrak_data.columns = dusttrak_data.columns.str.strip()

    # Specify the columns that need unit conversion (from [mg/m³] to (µg/m³))
    pm_columns = [
        "PM1 [mg/m3]",
        "PM2.5 [mg/m3]",
        "PM4 [mg/m3]",
        "PM10 [mg/m3]",
        "TOTAL [mg/m3]",
    ]

    # Check if the relevant columns exist before proceeding
    for col in pm_columns:
        if col in dusttrak_data.columns:
            # Determine new column name
            if col == "TOTAL [mg/m3]":
                new_col_name = "PM15 (µg/m³)"
            else:
                new_col_name = col.replace("[mg/m3]", "(µg/m³)")

            # Convert and assign to new column name
            dusttrak_data[new_col_name] = (
                dusttrak_data[col] * 1000
            )  # Convert from mg/m³ to µg/m³

    # Ensure datetime column is properly formatted
    dusttrak_data["datetime"] = pd.to_datetime(dusttrak_data["datetime"])

    # Filter data for the continuous date range from first burn to last burn
    filtered_data = dusttrak_data[
        (dusttrak_data["datetime"].dt.date >= first_burn_date)
        & (dusttrak_data["datetime"].dt.date <= last_burn_date)
    ]

    # Apply time shift (7 minutes) for DustTrak data on burn dates
    # This matches the time_shift value in the reference script
    time_shift_minutes = 7

    # Make a copy to avoid SettingWithCopyWarning
    filtered_data = filtered_data.copy()

    # Apply time shift to each burn date
    for _, row in burn_log.iterrows():
        burn_date = pd.to_datetime(row["Date"]).date()

        # Create mask for current burn date
        mask = filtered_data["datetime"].dt.date == burn_date

        # Apply time shift to this burn's data
        if mask.any():
            print(
                f"Applying {time_shift_minutes} minute time shift to DustTrak data for {row['Burn ID']} ({burn_date})"
            )
            filtered_data.loc[mask, "datetime"] += pd.Timedelta(
                minutes=time_shift_minutes
            )

    print(f"Loaded {len(filtered_data)} DustTrak records")
    return filtered_data


def process_vaisala_data():
    """
    Load and combine Vaisala humidity data from three Excel files.
    """
    print("Loading Vaisala data...")

    vaisala_files = [
        "./burn_data/vaisalaht/20240421-MH_Task_Logger_Data.xlsx",
        "./burn_data/vaisalaht/20240429-MH_Data_Processed.xlsx",
        "./burn_data/vaisalaht/20240531-MH_Data_Processed.xlsx",
    ]

    combined_data = pd.DataFrame()

    for file_path in vaisala_files:
        try:
            print(f"Processing {os.path.basename(file_path)}...")

            if "20240421" in file_path:
                # First file has T_RH sheet
                df = pd.read_excel(file_path, sheet_name="T_RH")
                # Create datetime column from Date and Time
                df["datetime"] = pd.to_datetime(
                    df["Date"].astype(str) + " " + df["Time"].astype(str),
                    errors="coerce",
                )
                df.drop(["Date", "Time"], axis=1, inplace=True)
            else:
                # Second and third files have only one sheet with same structure
                df = pd.read_excel(file_path)
                # Create datetime column from Date and Time
                df["datetime"] = pd.to_datetime(
                    df["Date"].astype(str) + " " + df["Time"].astype(str),
                    errors="coerce",
                )
                df.drop(["Date", "Time"], axis=1, inplace=True)

            # Append to combined data
            combined_data = pd.concat([combined_data, df], ignore_index=True)

        except Exception as e:
            print(f"Error processing {file_path}: {e}")

    # Filter data for the continuous date range from first burn to last burn
    filtered_data = combined_data[
        (combined_data["datetime"].dt.date >= first_burn_date)
        & (combined_data["datetime"].dt.date <= last_burn_date)
    ]

    # Sort by datetime
    filtered_data = filtered_data.sort_values("datetime").reset_index(drop=True)

    print(f"Loaded {len(filtered_data)} Vaisala records")
    return filtered_data


def add_burn_identifiers(df, datetime_col="datetime"):
    """
    Add a 'burn_id' column to identify which burn each data point belongs to.
    """
    df = df.copy()
    df["burn_id"] = None

    # Convert burn log dates to datetime
    burn_log["Date"] = pd.to_datetime(burn_log["Date"])

    # Add burn ID based on date
    for _, row in burn_log.iterrows():
        burn_id = row["Burn ID"]
        burn_date = row["Date"].date()

        # Mark data that falls on this burn date
        mask = df[datetime_col].dt.date == burn_date
        df.loc[mask, "burn_id"] = burn_id

    return df


def create_comparison_plots(dusttrak_data, vaisala_data, output_to_file=False):
    """
    Create comparison plots for DustTrak and Vaisala data.
    """
    # Create a unified plot with all burns
    print("Creating unified comparison plot...")

    # Set output to notebook by default
    output_notebook()

    # Define the date when DustTrak location changed (May 19, 2024)
    location_change_date = pd.to_datetime("2024-05-19").date()
    print(f"DustTrak location changed on: {location_change_date}")

    # Get burn IDs in numerical order (this is important for correct legend ordering)
    burn_numbers = [int(burn_id.replace("burn", "")) for burn_id in burn_log["Burn ID"]]
    sorted_burn_numbers = sorted(burn_numbers)
    sorted_burn_ids = [f"burn{num}" for num in sorted_burn_numbers]

    # Print RH statistics for outdoor RH
    outdoor_rh_min = vaisala_data["RH_Out_M4_C2"].min()
    outdoor_rh_max = vaisala_data["RH_Out_M4_C2"].max()
    print(f"\n--- RH STATISTICS ---")
    print(f"Outdoor RH: Min = {outdoor_rh_min:.1f}%, Max = {outdoor_rh_max:.1f}%")

    # Split Vaisala data by location change date for different RH columns
    vaisala_before = vaisala_data[
        vaisala_data["datetime"].dt.date < location_change_date
    ].copy()
    vaisala_after = vaisala_data[
        vaisala_data["datetime"].dt.date >= location_change_date
    ].copy()

    # Print RH statistics for indoor RH before location change
    if not vaisala_before.empty and "RH_Bed2_M3_C1" in vaisala_before.columns:
        indoor_rh_before_min = vaisala_before["RH_Bed2_M3_C1"].min()
        indoor_rh_before_max = vaisala_before["RH_Bed2_M3_C1"].max()
        print(
            f"Indoor RH (Bedroom, before {location_change_date}): Min = {indoor_rh_before_min:.1f}%, Max = {indoor_rh_before_max:.1f}%"
        )

    # Print RH statistics for indoor RH after location change
    if not vaisala_after.empty and "RH_Fam_M3_C4" in vaisala_after.columns:
        indoor_rh_after_min = vaisala_after["RH_Fam_M3_C4"].min()
        indoor_rh_after_max = vaisala_after["RH_Fam_M3_C4"].max()
        print(
            f"Indoor RH (Family Room, after {location_change_date}): Min = {indoor_rh_after_min:.1f}%, Max = {indoor_rh_after_max:.1f}%"
        )

    # Print RH statistics for each burn
    print("\n--- RH STATISTICS BY BURN ---")
    for burn_id in sorted_burn_ids:
        # Filter data for this burn
        v_burn_data = vaisala_data[vaisala_data["burn_id"] == burn_id]

        if not v_burn_data.empty:
            # Get burn date to determine which RH column to use
            burn_date = pd.to_datetime(
                burn_log[burn_log["Burn ID"] == burn_id]["Date"].iloc[0]
            ).date()

            # Choose the correct RH column based on date
            if burn_date < location_change_date:
                rh_column = "RH_Bed2_M3_C1"
                location = "Bedroom"
            else:
                rh_column = "RH_Fam_M3_C4"
                location = "Family Room"

            # Calculate and print min/max RH for this burn
            if rh_column in v_burn_data.columns:
                burn_rh_min = v_burn_data[rh_column].min()
                burn_rh_max = v_burn_data[rh_column].max()
                burn_label = BURN_LABELS[burn_id]
                print(
                    f"{burn_label} ({burn_date}, {location}): Min RH = {burn_rh_min:.1f}%, Max RH = {burn_rh_max:.1f}%"
                )

    print("\n--- OUTDOOR RH STATISTICS BY BURN ---")
    for burn_id in sorted_burn_ids:
        # Filter data for this burn
        v_burn_data = vaisala_data[vaisala_data["burn_id"] == burn_id]

        if not v_burn_data.empty and "RH_Out_M4_C2" in v_burn_data.columns:
            # Get burn date
            burn_date = pd.to_datetime(
                burn_log[burn_log["Burn ID"] == burn_id]["Date"].iloc[0]
            ).date()

            # Calculate and print min/max outdoor RH for this burn
            burn_outdoor_rh_min = v_burn_data["RH_Out_M4_C2"].min()
            burn_outdoor_rh_max = v_burn_data["RH_Out_M4_C2"].max()
            burn_label = BURN_LABELS[burn_id]
            print(
                f"{burn_label} ({burn_date}): Min Outdoor RH = {burn_outdoor_rh_min:.1f}%, Max Outdoor RH = {burn_outdoor_rh_max:.1f}%"
            )

    print("--- END OF RH STATISTICS ---\n")

    # ----- LINEAR PLOT -----
    # Create a Bokeh figure for all burns, linear scale
    p_linear = figure(
        width=1200,
        height=600,
        x_axis_type="datetime",
        title="DustTrak PM Total and Relative Humidity Comparison for All Burns",
        toolbar_location="above",
        x_range=(
            pd.to_datetime(first_burn_date),
            pd.to_datetime(last_burn_date)
            + pd.Timedelta(days=1)
            - pd.Timedelta(seconds=1),
        ),
    )

    # Set y-axis labels
    p_linear.yaxis.axis_label = "PM Total [µg/m³]"

    # Create a second y-axis for indoor Relative Humidity with the 25-65% range
    p_linear.extra_y_ranges = {
        "RH_indoor": Range1d(start=20, end=70),
        "RH_outdoor": Range1d(start=0, end=110),
    }
    p_linear.add_layout(
        LinearAxis(y_range_name="RH_indoor", axis_label="Indoor RH [%]"), "right"
    )

    # Add third y-axis for outdoor RH
    outdoor_axis = LinearAxis(y_range_name="RH_outdoor", axis_label="Outdoor RH [%]")
    outdoor_axis.axis_label_text_color = "green"
    p_linear.add_layout(outdoor_axis, "right")

    # Add background shading for the period after location change
    from bokeh.models import BoxAnnotation

    location_change_box = BoxAnnotation(
        left=pd.to_datetime(location_change_date),
        fill_color="lightgray",
        fill_alpha=0.2,
        line_color="gray",
        line_dash="dashed",
        line_width=1,
    )
    p_linear.add_layout(location_change_box)

    # Add outdoor RH data
    outdoor_rh_line = p_linear.line(
        vaisala_data["datetime"],
        vaisala_data["RH_Out_M4_C2"],
        color="green",
        line_width=1.5,
        alpha=0.2,
        y_range_name="RH_outdoor",
    )

    # Add text annotation for the location change
    from bokeh.models import Label

    location_change_label = Label(
        x=pd.to_datetime(location_change_date),
        y=5,
        text="DustTrak moved to morning room",
        text_font_size="9pt",
        text_color="gray",
        border_line_color=None,
        background_fill_color="white",
        background_fill_alpha=0.7,
    )
    p_linear.add_layout(location_change_label)

    # Initialize empty dictionaries to store line objects
    pm_lines = {}
    rh_lines = {}

    # Plot outdoor RH data first so it's behind everything else
    outdoor_rh_line = p_linear.line(
        vaisala_data["datetime"],
        vaisala_data["RH_Out_M4_C2"],
        color="green",
        line_width=1.5,
        alpha=0.2,
        y_range_name="RH_outdoor",
    )

    # Now plot the full data (will appear behind the burn data but on top of outdoor RH)
    # First plot the full data (will appear behind the burn data)
    # PM Total for full period
    full_pm_line = p_linear.line(
        dusttrak_data["datetime"],
        dusttrak_data["PM15 (µg/m³)"],
        color="gray",
        line_width=1.5,
        alpha=0.5,
    )

    # RH data - plotted in two segments with different columns
    if not vaisala_before.empty:
        full_rh_line_before = p_linear.line(
            vaisala_before["datetime"],
            vaisala_before["RH_Bed2_M3_C1"],
            color="lightblue",
            line_width=1.5,
            alpha=0.5,
            y_range_name="RH_indoor",
        )

    if not vaisala_after.empty:
        full_rh_line_after = p_linear.line(
            vaisala_after["datetime"],
            vaisala_after["RH_Fam_M3_C4"],
            color="lightblue",
            line_width=1.5,
            alpha=0.5,
            y_range_name="RH_indoor",
        )

    # Plot each burn with highlighting
    for burn_id in sorted_burn_ids:
        # Filter data for this burn
        dt_burn_data = dusttrak_data[dusttrak_data["burn_id"] == burn_id]
        v_burn_data = vaisala_data[vaisala_data["burn_id"] == burn_id]

        if not dt_burn_data.empty:
            # Plot PM Total from DustTrak
            pm_lines[burn_id] = p_linear.line(
                dt_burn_data["datetime"],
                dt_burn_data["PM15 (µg/m³)"],
                color=BURN_STYLES[burn_id]["color"],
                line_dash=BURN_STYLES[burn_id]["line_dash"],
                line_width=2,
            )

        if not v_burn_data.empty:
            # Get burn date to determine which RH column to use
            burn_date = pd.to_datetime(
                burn_log[burn_log["Burn ID"] == burn_id]["Date"].iloc[0]
            ).date()

            # Choose the correct RH column based on date
            if burn_date < location_change_date:
                rh_column = "RH_Bed2_M3_C1"
            else:
                rh_column = "RH_Fam_M3_C4"

            # Plot Relative Humidity from Vaisala with appropriate column
            if rh_column in v_burn_data.columns:
                rh_lines[burn_id] = p_linear.line(
                    v_burn_data["datetime"],
                    v_burn_data[rh_column],
                    color=BURN_STYLES[burn_id]["color"],
                    line_dash="dotted",
                    line_width=2,
                    y_range_name="RH_indoor",
                )

    # Construct legend items in the desired order
    legend_items = []

    # First add all PM lines in burn order
    for burn_id in sorted_burn_ids:
        if burn_id in pm_lines:
            legend_items.append(
                (f"{BURN_LABELS[burn_id]} - PM Total", [pm_lines[burn_id]])
            )

    # Add full PM line to legend
    legend_items.append(("Full Period PM Data", [full_pm_line]))

    # Then add all RH lines in burn order
    for burn_id in sorted_burn_ids:
        if burn_id in rh_lines:
            legend_items.append((f"{BURN_LABELS[burn_id]} - RH", [rh_lines[burn_id]]))

    # Add full RH line to legend - use before or after based on availability
    if "full_rh_line_before" in locals() and "full_rh_line_after" in locals():
        # If both exist, use a list of both lines
        legend_items.append(
            ("Full Period Indoor RH", [full_rh_line_before, full_rh_line_after])
        )
    elif "full_rh_line_before" in locals():
        legend_items.append(("Full Period Indoor RH", [full_rh_line_before]))
    elif "full_rh_line_after" in locals():
        legend_items.append(("Full Period Indoor RH", [full_rh_line_after]))

    # Add outdoor RH line to legend (last)
    legend_items.append(("Outdoor RH", [outdoor_rh_line]))

    # Add legend with all items in the correct order
    legend = Legend(items=legend_items, location="top_right")
    p_linear.add_layout(legend, "right")
    p_linear.legend.click_policy = "hide"

    # Format the plot
    p_linear.axis.axis_label_text_font = "Calibri"
    p_linear.axis.axis_label_text_font_size = "12pt"
    p_linear.axis.axis_label_text_font_style = "normal"
    p_linear.title.align = "center"

    # ----- LOG PLOT -----
    # Create a Bokeh figure for all burns, log scale
    p_log = figure(
        width=1200,
        height=600,
        x_axis_type="datetime",
        y_axis_type="log",
        title="DustTrak PM Total (Log Scale) and Relative Humidity Comparison for All Burns",
        toolbar_location="above",
        x_range=(
            pd.to_datetime(first_burn_date),
            pd.to_datetime(last_burn_date)
            + pd.Timedelta(days=1)
            - pd.Timedelta(seconds=1),
        ),
    )

    # Set y-axis labels
    p_log.yaxis.axis_label = "PM Total [µg/m³]"

    # Create a second y-axis for indoor Relative Humidity with the 25-65% range
    p_log.extra_y_ranges = {
        "RH_indoor": Range1d(start=20, end=70),
        "RH_outdoor": Range1d(start=0, end=110),
    }
    p_log.add_layout(
        LinearAxis(y_range_name="RH_indoor", axis_label="Indoor RH [%]"), "right"
    )

    # Add third y-axis for outdoor RH (0-100%)
    log_outdoor_axis = LinearAxis(
        y_range_name="RH_outdoor", axis_label="Outdoor RH [%]"
    )
    log_outdoor_axis.axis_label_text_color = "green"
    p_log.add_layout(log_outdoor_axis, "right")

    # Add background shading for the period after location change
    location_change_box_log = BoxAnnotation(
        left=pd.to_datetime(location_change_date),
        fill_color="lightgray",
        fill_alpha=0.2,
        line_color="gray",
        line_dash="dashed",
        line_width=1,
    )
    p_log.add_layout(location_change_box_log)

    # Add outdoor RH data to log plot
    outdoor_rh_line_log = p_log.line(
        vaisala_data["datetime"],
        vaisala_data["RH_Out_M4_C2"],
        color="green",
        line_width=1.5,
        alpha=0.2,
        y_range_name="RH_outdoor",
    )

    # Add text annotation for the location change
    location_change_label_log = Label(
        x=pd.to_datetime(location_change_date),
        y=10,
        text="DustTrak moved to morning room",
        text_font_size="9pt",
        text_color="gray",
        border_line_color=None,
        background_fill_color="white",
        background_fill_alpha=0.7,
    )
    p_log.add_layout(location_change_label_log)

    # Initialize empty dictionaries to store line objects for log plot
    log_pm_lines = {}
    log_rh_lines = {}

    # Plot outdoor RH data first so it's behind everything else
    outdoor_rh_line_log = p_log.line(
        vaisala_data["datetime"],
        vaisala_data["RH_Out_M4_C2"],
        color="green",
        line_width=1.5,
        alpha=0.2,
        y_range_name="RH_outdoor",
    )

    # Now plot the full data for log plot
    log_full_pm_line = p_log.line(
        dusttrak_data["datetime"],
        dusttrak_data["PM15 (µg/m³)"],
        color="gray",
        line_width=1.5,
        alpha=0.5,
    )

    # RH data for log plot - plotted in two segments with different columns
    if not vaisala_before.empty:
        log_full_rh_line_before = p_log.line(
            vaisala_before["datetime"],
            vaisala_before["RH_Bed2_M3_C1"],
            color="lightblue",
            line_width=1.5,
            alpha=0.5,
            y_range_name="RH_indoor",
        )

    if not vaisala_after.empty:
        log_full_rh_line_after = p_log.line(
            vaisala_after["datetime"],
            vaisala_after["RH_Fam_M3_C4"],
            color="lightblue",
            line_width=1.5,
            alpha=0.5,
            y_range_name="RH_indoor",
        )

    # Plot each burn with highlighting on log scale plot
    for burn_id in sorted_burn_ids:
        # Filter data for this burn
        dt_burn_data = dusttrak_data[dusttrak_data["burn_id"] == burn_id]
        v_burn_data = vaisala_data[vaisala_data["burn_id"] == burn_id]

        if not dt_burn_data.empty:
            # Plot PM Total from DustTrak
            log_pm_lines[burn_id] = p_log.line(
                dt_burn_data["datetime"],
                dt_burn_data["PM15 (µg/m³)"],
                color=BURN_STYLES[burn_id]["color"],
                line_dash=BURN_STYLES[burn_id]["line_dash"],
                line_width=2,
            )

        if not v_burn_data.empty:
            # Get burn date to determine which RH column to use
            burn_date = pd.to_datetime(
                burn_log[burn_log["Burn ID"] == burn_id]["Date"].iloc[0]
            ).date()

            # Choose the correct RH column based on date
            if burn_date < location_change_date:
                rh_column = "RH_Bed2_M3_C1"
            else:
                rh_column = "RH_Fam_M3_C4"

            # Plot Relative Humidity from Vaisala with appropriate column
            if rh_column in v_burn_data.columns:
                log_rh_lines[burn_id] = p_log.line(
                    v_burn_data["datetime"],
                    v_burn_data[rh_column],
                    color=BURN_STYLES[burn_id]["color"],
                    line_dash="dotted",
                    line_width=2,
                    y_range_name="RH_indoor",
                )

    # Construct legend items for log plot in the desired order
    log_legend_items = []

    # First add all PM lines in burn order
    for burn_id in sorted_burn_ids:
        if burn_id in log_pm_lines:
            log_legend_items.append(
                (f"{BURN_LABELS[burn_id]} - PM Total", [log_pm_lines[burn_id]])
            )

    # Add full PM line to legend
    log_legend_items.append(("Full Period PM Data", [log_full_pm_line]))

    # Then add all RH lines in burn order
    for burn_id in sorted_burn_ids:
        if burn_id in log_rh_lines:
            log_legend_items.append(
                (f"{BURN_LABELS[burn_id]} - RH", [log_rh_lines[burn_id]])
            )

    # Add full RH line to legend - use before or after based on availability
    if "log_full_rh_line_before" in locals() and "log_full_rh_line_after" in locals():
        # If both exist, use a list of both lines
        log_legend_items.append(
            ("Full Period Indoor RH", [log_full_rh_line_before, log_full_rh_line_after])
        )
    elif "log_full_rh_line_before" in locals():
        log_legend_items.append(("Full Period Indoor RH", [log_full_rh_line_before]))
    elif "log_full_rh_line_after" in locals():
        log_legend_items.append(("Full Period Indoor RH", [log_full_rh_line_after]))

    # Add outdoor RH line to legend (last)
    log_legend_items.append(("Outdoor RH", [outdoor_rh_line_log]))

    # Add legend with all items in the correct order
    log_legend = Legend(items=log_legend_items, location="top_right")
    p_log.add_layout(log_legend, "right")
    p_log.legend.click_policy = "hide"

    # Format the log plot
    p_log.axis.axis_label_text_font = "Calibri"
    p_log.axis.axis_label_text_font_size = "12pt"
    p_log.axis.axis_label_text_font_style = "normal"
    p_log.title.align = "center"

    # Get script metadata
    metadata = get_script_metadata()

    # Add metadata to plots using Div elements
    from bokeh.models import Div

    # Create additional context information
    location_change_info = f"DustTrak location changed on: {location_change_date}"
    bedroom_rh_range = "Indoor RH (Bedroom): 26-55%"
    kitchen_rh_range = "Indoor RH (Family Room): 41-64%"
    outdoor_rh_range = "Outdoor RH: 19-103%"

    # Create metadata div for linear plot with additional information
    linear_metadata_div = Div(
        text=f"<small>{location_change_info}<br>{bedroom_rh_range} | {kitchen_rh_range} | {outdoor_rh_range}<br>{metadata}</small>",
        width=1200,
    )
    linear_layout = column(p_linear, linear_metadata_div)

    # Create metadata div for log plot with additional information
    log_metadata_div = Div(
        text=f"<small>{location_change_info}<br>{bedroom_rh_range} | {kitchen_rh_range} | {outdoor_rh_range}<br>{metadata}</small>",
        width=1200,
    )
    log_layout = column(p_log, log_metadata_div)

    # Display plots in notebook with metadata
    show(linear_layout)
    show(log_layout)

    # Define the output file paths
    if output_to_file:
        output_file("./Paper_figures/DustTrak_and_RH_linear.html")
        show(linear_layout)
        output_file("./Paper_figures/DustTrak_and_RH_log.html")
        show(log_layout)

    return p_linear, p_log


def main(output_to_file=False):
    """
    Main function to run the script.

    Parameters:
        output_to_file (bool): Whether to also output to HTML files
    """
    # Process data
    dusttrak_data = process_dusttrak_data()
    vaisala_data = process_vaisala_data()

    # Add burn identifiers to the data
    dusttrak_data = add_burn_identifiers(dusttrak_data)
    vaisala_data = add_burn_identifiers(vaisala_data)

    # Create comparison plots
    create_comparison_plots(dusttrak_data, vaisala_data, output_to_file)


# Run script
if __name__ == "__main__":
    # Set to True to output to file, False for notebook only
    output_to_file = True
    main(output_to_file)
# %%
